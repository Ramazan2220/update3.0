import logging
import numpy as np
import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import pickle

logger = logging.getLogger(__name__)

@dataclass
class AccountFeatures:
    """–§–∏—á–∏ –¥–ª—è ML –º–æ–¥–µ–ª–∏"""
    # –ë–∞–∑–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
    account_age_days: float = 0
    follower_count: float = 0
    following_count: float = 0
    media_count: float = 0
    
    # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
    posts_last_week: float = 0
    stories_last_week: float = 0
    likes_given_last_week: float = 0
    comments_last_week: float = 0
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è
    avg_daily_actions: float = 0
    action_variety_score: float = 0
    timing_consistency: float = 0
    human_behavior_score: float = 0
    
    # API –º–µ—Ç—Ä–∏–∫–∏
    api_errors_last_week: float = 0
    challenge_requests_last_week: float = 0
    rate_limit_hits_last_week: float = 0
    response_time_avg: float = 0
    
    # Engagement –º–µ—Ç—Ä–∏–∫–∏
    engagement_rate: float = 0
    follower_growth_rate: float = 0
    unfollower_rate: float = 0
    
    # –ü—Ä–æ–∫—Å—ñ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
    proxy_changes_last_month: float = 0
    device_changes_last_month: float = 0
    location_changes: float = 0
    
    def to_array(self) -> np.ndarray:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ –º–∞—Å—Å–∏–≤ –¥–ª—è ML –º–æ–¥–µ–ª–∏"""
        return np.array([
            self.account_age_days, self.follower_count, self.following_count, self.media_count,
            self.posts_last_week, self.stories_last_week, self.likes_given_last_week, self.comments_last_week,
            self.avg_daily_actions, self.action_variety_score, self.timing_consistency, self.human_behavior_score,
            self.api_errors_last_week, self.challenge_requests_last_week, self.rate_limit_hits_last_week, self.response_time_avg,
            self.engagement_rate, self.follower_growth_rate, self.unfollower_rate,
            self.proxy_changes_last_month, self.device_changes_last_month, self.location_changes
        ])

@dataclass 
class MLPrediction:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
    health_score: float
    ban_risk_score: float
    confidence: float
    risk_factors: List[str]
    recommendations: List[str]
    feature_importance: Dict[str, float]

class SimpleMLModel:
    """–ü—Ä–æ—Å—Ç–∞—è ML –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Å–æ–≤ (–±–µ–∑ sklearn)"""
    
    def __init__(self):
        # –í–µ—Å–∞ –¥–ª—è health score (–Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏)
        self.health_weights = np.array([
            0.15,  # account_age_days
            0.08,  # follower_count  
            0.05,  # following_count
            0.07,  # media_count
            0.10,  # posts_last_week
            0.08,  # stories_last_week
            0.06,  # likes_given_last_week
            0.04,  # comments_last_week
            0.12,  # avg_daily_actions
            0.10,  # action_variety_score
            0.08,  # timing_consistency
            0.15,  # human_behavior_score
            -0.20, # api_errors_last_week (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π)
            -0.25, # challenge_requests_last_week (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π)
            -0.15, # rate_limit_hits_last_week (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π)
            -0.05, # response_time_avg (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π)
            0.12,  # engagement_rate
            0.08,  # follower_growth_rate
            -0.10, # unfollower_rate (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π)
            -0.08, # proxy_changes_last_month (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π)
            -0.06, # device_changes_last_month (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π)
            -0.04  # location_changes (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π)
        ])
        
        # –í–µ—Å–∞ –¥–ª—è ban risk (–∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ health)
        self.ban_risk_weights = -self.health_weights * 0.8
        self.ban_risk_weights[12:16] *= -2  # –£–¥–≤–∞–∏–≤–∞–µ–º –≤–ª–∏—è–Ω–∏–µ –æ—à–∏–±–æ–∫ API
        
    def predict_health(self, features: AccountFeatures) -> float:
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç health score"""
        feature_array = features.to_array()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ñ–∏—á–∏
        normalized_features = self._normalize_features(feature_array)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–∫–æ—Ä
        raw_score = np.dot(normalized_features, self.health_weights)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º sigmoid –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è score 0-100
        health_score = 100 / (1 + np.exp(-raw_score))
        
        return max(0, min(100, health_score))
    
    def predict_ban_risk(self, features: AccountFeatures) -> float:
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç ban risk"""
        feature_array = features.to_array()
        normalized_features = self._normalize_features(feature_array)
        
        raw_score = np.dot(normalized_features, self.ban_risk_weights)
        ban_risk = 100 / (1 + np.exp(-raw_score))
        
        return max(0, min(100, ban_risk))
    
    def _normalize_features(self, features: np.ndarray) -> np.ndarray:
        """–ü—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∏—á"""
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö —á–∏—Å–µ–ª
        normalized = features.copy()
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º log(1+x) –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        for i, val in enumerate(normalized):
            if val > 0:
                normalized[i] = np.log1p(val)
            else:
                normalized[i] = val
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [-1, 1]
        max_val = np.max(np.abs(normalized))
        if max_val > 0:
            normalized = normalized / max_val
            
        return normalized

class MLHealthPredictor:
    """ML —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–¥–æ—Ä–æ–≤—å—è –∞–∫–∫–∞—É–Ω—Ç–æ–≤"""
    
    def __init__(self, model_path: str = "data/ml_models"):
        self.model_path = model_path
        self.model = SimpleMLModel()
        self.feature_names = [
            'account_age_days', 'follower_count', 'following_count', 'media_count',
            'posts_last_week', 'stories_last_week', 'likes_given_last_week', 'comments_last_week',
            'avg_daily_actions', 'action_variety_score', 'timing_consistency', 'human_behavior_score',
            'api_errors_last_week', 'challenge_requests_last_week', 'rate_limit_hits_last_week', 'response_time_avg',
            'engagement_rate', 'follower_growth_rate', 'unfollower_rate',
            'proxy_changes_last_month', 'device_changes_last_month', 'location_changes'
        ]
        
        # –ö—ç—à –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        self.predictions_cache = {}
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –º–æ–¥–µ–ª–µ–π
        os.makedirs(model_path, exist_ok=True)
        
    def predict_account_health(self, account_id: int, client=None) -> MLPrediction:
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–¥–æ—Ä–æ–≤—å—è –∞–∫–∫–∞—É–Ω—Ç–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            if account_id in self.predictions_cache:
                cache_time = self.predictions_cache[account_id].get('timestamp', 0)
                if datetime.now().timestamp() - cache_time < 1800:  # 30 –º–∏–Ω—É—Ç
                    return self.predictions_cache[account_id]['prediction']
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏—á–∏
            features = self._extract_account_features(account_id, client)
            
            # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            health_score = self.model.predict_health(features)
            ban_risk = self.model.predict_ban_risk(features)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º confidence
            confidence = self._calculate_confidence(features)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞
            risk_factors = self._identify_risk_factors(features)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = self._generate_recommendations(features, health_score, ban_risk)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å —Ñ–∏—á
            feature_importance = self._calculate_feature_importance(features)
            
            prediction = MLPrediction(
                health_score=health_score,
                ban_risk_score=ban_risk,
                confidence=confidence,
                risk_factors=risk_factors,
                recommendations=recommendations,
                feature_importance=feature_importance
            )
            
            # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.predictions_cache[account_id] = {
                'prediction': prediction,
                'timestamp': datetime.now().timestamp()
            }
            
            logger.info(f"ü§ñ ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∞–∫–∫–∞—É–Ω—Ç–∞ {account_id}: Health {health_score:.1f}, Risk {ban_risk:.1f}, Confidence {confidence:.1f}")
            
            return prediction
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            return MLPrediction(
                health_score=50.0,
                ban_risk_score=50.0,
                confidence=0.3,
                risk_factors=['insufficient_data'],
                recommendations=['collect_more_data'],
                feature_importance={}
            )
    
    def _extract_account_features(self, account_id: int, client=None) -> AccountFeatures:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∏—á–∏ –∞–∫–∫–∞—É–Ω—Ç–∞ –¥–ª—è ML –º–æ–¥–µ–ª–∏"""
        from database.db_manager import get_instagram_account
        
        features = AccountFeatures()
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ë–î
            account = get_instagram_account(account_id)
            if account:
                # –í–æ–∑—Ä–∞—Å—Ç –∞–∫–∫–∞—É–Ω—Ç–∞
                if account.created_at:
                    features.account_age_days = (datetime.now() - account.created_at).days
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (–µ—Å–ª–∏ –µ—Å—Ç—å)
                if hasattr(account, 'stats') and account.stats:
                    try:
                        stats = json.loads(account.stats) if isinstance(account.stats, str) else account.stats
                        features.follower_count = stats.get('follower_count', 0)
                        features.following_count = stats.get('following_count', 0)
                        features.media_count = stats.get('media_count', 0)
                        features.engagement_rate = stats.get('engagement_rate', 0)
                    except:
                        pass
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ Instagram API
            if client:
                try:
                    user_info = client.user_info(client.user_id)
                    features.follower_count = user_info.follower_count
                    features.following_count = user_info.following_count
                    features.media_count = user_info.media_count
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
                    activity_features = self._analyze_recent_activity(client)
                    features.posts_last_week = activity_features.get('posts', 0)
                    features.engagement_rate = activity_features.get('engagement_rate', 0)
                    
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ API: {e}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (–∑–∞–≥–ª—É—à–∫–∞)
            activity_analysis = self._analyze_activity_logs(account_id)
            features.avg_daily_actions = activity_analysis.get('avg_daily_actions', 0)
            features.action_variety_score = activity_analysis.get('variety_score', 0)
            features.timing_consistency = activity_analysis.get('timing_consistency', 0)
            features.human_behavior_score = activity_analysis.get('human_score', 50)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ API (–∑–∞–≥–ª—É—à–∫–∞)
            error_analysis = self._analyze_api_errors(account_id)
            features.api_errors_last_week = error_analysis.get('errors', 0)
            features.challenge_requests_last_week = error_analysis.get('challenges', 0)
            features.rate_limit_hits_last_week = error_analysis.get('rate_limits', 0)
            features.response_time_avg = error_analysis.get('avg_response_time', 1.0)
            
            logger.info(f"üìä –ò–∑–≤–ª–µ—á–µ–Ω—ã —Ñ–∏—á–∏ –¥–ª—è –∞–∫–∫–∞—É–Ω—Ç–∞ {account_id}: –≤–æ–∑—Ä–∞—Å—Ç {features.account_age_days} –¥–Ω–µ–π, –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ {features.follower_count}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∏—á: {e}")
        
        return features
    
    def _analyze_recent_activity(self, client) -> Dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–µ–¥–∞–≤–Ω—é—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞–∫–∫–∞—É–Ω—Ç–∞"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø–æ—Å—Ç—ã
            recent_media = client.user_medias(client.user_id, amount=20)
            
            # –°—á–∏—Ç–∞–µ–º –ø–æ—Å—Ç—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é
            week_ago = datetime.now() - timedelta(days=7)
            posts_last_week = sum(1 for media in recent_media if media.taken_at >= week_ago)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º engagement rate
            if recent_media:
                total_engagement = sum(media.like_count + media.comment_count for media in recent_media[:10])
                avg_engagement = total_engagement / len(recent_media[:10])
                follower_count = client.user_info(client.user_id).follower_count
                engagement_rate = (avg_engagement / max(follower_count, 1)) * 100
            else:
                engagement_rate = 0
            
            return {
                'posts': posts_last_week,
                'engagement_rate': engagement_rate
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {e}")
            return {'posts': 0, 'engagement_rate': 0}
    
    def _analyze_activity_logs(self, account_id: int) -> Dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–æ–≥–∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∞–∫–∫–∞—É–Ω—Ç–∞"""
        # –ó–∞–≥–ª—É—à–∫–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã –∞–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤
        return {
            'avg_daily_actions': random.uniform(10, 100),
            'variety_score': random.uniform(30, 90),
            'timing_consistency': random.uniform(40, 85),
            'human_score': random.uniform(50, 95)
        }
    
    def _analyze_api_errors(self, account_id: int) -> Dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—à–∏–±–∫–∏ API –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è"""
        # –ó–∞–≥–ª—É—à–∫–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã –∞–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤ –æ—à–∏–±–æ–∫
        return {
            'errors': random.uniform(0, 10),
            'challenges': random.uniform(0, 3),
            'rate_limits': random.uniform(0, 5),
            'avg_response_time': random.uniform(0.5, 3.0)
        }
    
    def _calculate_confidence(self, features: AccountFeatures) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏"""
        # –ü—Ä–æ—Å—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞ –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        feature_array = features.to_array()
        non_zero_features = np.count_nonzero(feature_array)
        total_features = len(feature_array)
        
        data_completeness = non_zero_features / total_features
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º –≤–æ–∑—Ä–∞—Å—Ç –∞–∫–∫–∞—É–Ω—Ç–∞ (–±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö = –±–æ–ª—å—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏)
        age_factor = min(features.account_age_days / 30, 1.0)  # –ú–∞–∫—Å–∏–º—É–º —á–µ—Ä–µ–∑ 30 –¥–Ω–µ–π
        
        confidence = (data_completeness * 0.7 + age_factor * 0.3) * 100
        return max(30, min(95, confidence))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤ —Ä–∞–∑—É–º–Ω—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö
    
    def _identify_risk_factors(self, features: AccountFeatures) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞"""
        risk_factors = []
        
        if features.api_errors_last_week > 5:
            risk_factors.append('high_api_error_rate')
        
        if features.challenge_requests_last_week > 2:
            risk_factors.append('frequent_challenges')
        
        if features.rate_limit_hits_last_week > 3:
            risk_factors.append('rate_limiting_issues')
        
        if features.account_age_days < 7:
            risk_factors.append('new_account')
        
        if features.human_behavior_score < 40:
            risk_factors.append('non_human_patterns')
        
        if features.avg_daily_actions > 200:
            risk_factors.append('excessive_activity')
        
        if features.proxy_changes_last_month > 5:
            risk_factors.append('frequent_proxy_changes')
        
        if features.unfollower_rate > 20:
            risk_factors.append('high_unfollow_rate')
        
        return risk_factors
    
    def _generate_recommendations(self, features: AccountFeatures, health_score: float, ban_risk: float) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∑–¥–æ—Ä–æ–≤—å—è –∞–∫–∫–∞—É–Ω—Ç–∞"""
        recommendations = []
        
        if ban_risk > 70:
            recommendations.append('–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–∞ 24-48 —á–∞—Å–æ–≤')
            recommendations.append('–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ —Å–º–µ–Ω–∏—Ç—å –ø—Ä–æ–∫—Å–∏')
        elif ban_risk > 40:
            recommendations.append('–°–Ω–∏–∑–∏—Ç—å –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞ 50%')
            recommendations.append('–£–≤–µ–ª–∏—á–∏—Ç—å –∑–∞–¥–µ—Ä–∂–∫–∏ –º–µ–∂–¥—É –¥–µ–π—Å—Ç–≤–∏—è–º–∏')
        
        if health_score < 50:
            recommendations.append('–ü—Ä–æ–≤–µ—Å—Ç–∏ –º—è–≥–∫–∏–π –ø—Ä–æ–≥—Ä–µ–≤ –≤ —Ç–µ—á–µ–Ω–∏–µ 2-3 –¥–Ω–µ–π')
            recommendations.append('–°–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è –Ω–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞')
        
        if features.human_behavior_score < 50:
            recommendations.append('–£–ª—É—á—à–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è - –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏')
            recommendations.append('–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —á–µ–ª–æ–≤–µ–∫–æ–ø–æ–¥–æ–±–Ω—ã–µ –∑–∞–¥–µ—Ä–∂–∫–∏')
        
        if features.api_errors_last_week > 3:
            recommendations.append('–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∫—Å–∏ –∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è')
            recommendations.append('–û–±–Ω–æ–≤–∏—Ç—å –∫–ª–∏–µ–Ω—Ç Instagram API')
        
        if features.engagement_rate < 1:
            recommendations.append('–£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è engagement')
            recommendations.append('–ë—ã—Ç—å –±–æ–ª–µ–µ –∞–∫—Ç–∏–≤–Ω—ã–º –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö –∏ –ª–∞–π–∫–∞—Ö')
        
        if not recommendations:
            recommendations.append('–ü—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é - –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Ö–æ—Ä–æ—à–∏–µ')
        
        return recommendations
    
    def _calculate_feature_importance(self, features: AccountFeatures) -> Dict[str, float]:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–π —Ñ–∏—á–∏"""
        feature_array = features.to_array()
        importance = {}
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ä–∞—Å—á–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏
        for i, feature_name in enumerate(self.feature_names):
            weight = abs(self.model.health_weights[i])
            value = abs(feature_array[i])
            importance[feature_name] = weight * (1 + np.log1p(value))
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        total_importance = sum(importance.values())
        if total_importance > 0:
            importance = {k: (v / total_importance) * 100 for k, v in importance.items()}
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-5 –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã—Ö —Ñ–∏—á
        sorted_importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)
        return dict(sorted_importance[:5])
    
    def train_model_with_feedback(self, account_id: int, actual_outcome: str, features: AccountFeatures):
        """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ (–ø—Ä–æ—Å—Ç–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤)"""
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Å—Ö–µ–º–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∏–¥–±–µ–∫–∞
            if actual_outcome == 'banned':
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
                self.model.ban_risk_weights *= 1.01
            elif actual_outcome == 'healthy':
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
                self.model.health_weights *= 1.01
            
            logger.info(f"üìö –ú–æ–¥–µ–ª—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∏–¥–±–µ–∫–∞ –¥–ª—è –∞–∫–∫–∞—É–Ω—Ç–∞ {account_id}: {actual_outcome}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            self._save_model()
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
    
    def _save_model(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –¥–∏—Å–∫"""
        try:
            model_file = os.path.join(self.model_path, 'health_predictor_model.pkl')
            with open(model_file, 'wb') as f:
                pickle.dump(self.model, f)
            logger.info("üíæ ML –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å —Å –¥–∏—Å–∫–∞"""
        try:
            model_file = os.path.join(self.model_path, 'health_predictor_model.pkl')
            if os.path.exists(model_file):
                with open(model_file, 'rb') as f:
                    self.model = pickle.load(f)
                logger.info("üìÇ ML –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")

# –ü—Ä–æ—Å—Ç–æ–π random –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
import random

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–∏—Å—Ç–µ–º–æ–π
def get_ml_health_predictor():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä ML –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞ –∑–¥–æ—Ä–æ–≤—å—è"""
    return MLHealthPredictor() 
#!/usr/bin/env python3
"""
üî• FakeRedis - –≠–º—É–ª—è—Ç–æ—Ä Redis –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ —Å –º–µ–∂–ø—Ä–æ—Ü–µ—Å—Å–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
"""

import json
import os
import time
import threading
import logging
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta
import fcntl  # –î–ª—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ —Ñ–∞–π–ª–æ–≤

logger = logging.getLogger(__name__)

class FakeRedisFileBased:
    """FakeRedis —Å –ø–æ–ª–Ω–æ–π —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –º–µ–∂–ø—Ä–æ—Ü–µ—Å—Å–Ω–æ–π —Å–≤—è–∑–∏"""
    
    def __init__(self):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –¥–ª—è –º–µ–∂–ø—Ä–æ—Ü–µ—Å—Å–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        project_root = os.path.dirname(os.path.abspath(__file__))
        self.data_dir = os.path.join(project_root, "data", "fake_redis")
        self.sync_file = os.path.join(self.data_dir, "data.json")
        self.messages_dir = os.path.join(self.data_dir, "messages")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(self.messages_dir, exist_ok=True)
        
        self._data = {}
        self._lock = threading.Lock()
        self._subscribers = {}  # –ö–∞–Ω–∞–ª—ã –ø–æ–¥–ø–∏—Å–æ–∫
        
        self._load_from_file()
        logger.info("üî• FakeRedis —Å —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π –∑–∞–ø—É—â–µ–Ω")
    
    def _safe_file_operation(self, filename: str, operation: str, data: Any = None):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è —Å —Ñ–∞–π–ª–æ–º —Å –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π"""
        try:
            with open(filename, 'a+' if operation == 'read' else 'w') as f:
                # –ë–ª–æ–∫–∏—Ä—É–µ–º —Ñ–∞–π–ª
                fcntl.flock(f.fileno(), fcntl.LOCK_EX)
                
                if operation == 'read':
                    f.seek(0)
                    content = f.read()
                    return json.loads(content) if content.strip() else {}
                elif operation == 'write':
                    json.dump(data, f, indent=2)
                    f.flush()
                    os.fsync(f.fileno())
                    return True
                    
        except (FileNotFoundError, json.JSONDecodeError):
            return {} if operation == 'read' else False
        except Exception as e:
            logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ñ–∞–π–ª–æ–≤–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏ {operation}: {e}")
            return {} if operation == 'read' else False
    
    def _load_from_file(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞"""
        data = self._safe_file_operation(self.sync_file, 'read')
        with self._lock:
            self._data = data.get('data', {})
    
    def _save_to_file(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª"""
        data_to_save = {
            'data': self._data,
            'timestamp': datetime.now().isoformat()
        }
        self._safe_file_operation(self.sync_file, 'write', data_to_save)
    
    def set(self, key: str, value: str, ex: Optional[int] = None) -> bool:
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∫–ª—é—á–∞"""
        with self._lock:
            self._data[key] = value
            self._save_to_file()
            logger.debug(f"Redis SET: {key} = {value}")
            return True
    
    def get(self, key: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∫–ª—é—á–∞"""
        self._load_from_file()  # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        return self._data.get(key)
    
    def delete(self, key: str) -> bool:
        """–£–¥–∞–ª—è–µ—Ç –∫–ª—é—á"""
        with self._lock:
            if key in self._data:
                del self._data[key]
                self._save_to_file()
                logger.debug(f"Redis DELETE: {key}")
                return True
            return False
    
    def hset(self, key: str, field: str, value: str) -> bool:
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–æ–ª–µ –≤ —Ö–µ—à–µ"""
        with self._lock:
            if key not in self._data:
                self._data[key] = "{}"
            
            try:
                hash_data = json.loads(self._data[key])
            except:
                hash_data = {}
            
            hash_data[field] = value
            self._data[key] = json.dumps(hash_data)
            self._save_to_file()
            logger.debug(f"Redis HSET: {key}.{field} = {value}")
            return True
    
    def hget(self, key: str, field: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–µ –∏–∑ —Ö–µ—à–∞"""
        self._load_from_file()  # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        
        if key not in self._data:
            return None
        
        try:
            hash_data = json.loads(self._data[key])
            return hash_data.get(field)
        except:
            return None
    
    def hdel(self, key: str, field: str) -> bool:
        """–£–¥–∞–ª—è–µ—Ç –ø–æ–ª–µ –∏–∑ —Ö–µ—à–∞"""
        with self._lock:
            if key not in self._data:
                return False
            
            try:
                hash_data = json.loads(self._data[key])
                if field in hash_data:
                    del hash_data[field]
                    self._data[key] = json.dumps(hash_data)
                    self._save_to_file()
                    logger.debug(f"Redis HDEL: {key}.{field}")
                    return True
            except:
                pass
            return False

    def hgetall(self, key: str) -> Dict[str, str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –ø–æ–ª—è –∏–∑ —Ö–µ—à–∞"""
        self._load_from_file()  # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        
        if key not in self._data:
            return {}
        
        try:
            hash_data = json.loads(self._data[key])
            return hash_data
        except:
            return {}

    def exists(self, key: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–∞"""
        self._load_from_file()  # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        return key in self._data

    def keys(self, pattern: str = "*") -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –∫–ª—é—á–∏ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É"""
        self._load_from_file()  # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        
        if pattern == "*":
            return list(self._data.keys())
        else:
            # –ü—Ä–æ—Å—Ç–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            pattern_clean = pattern.replace("*", "")
            return [k for k in self._data.keys() if pattern_clean in k]

    def lpush(self, key: str, value: str) -> int:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —ç–ª–µ–º–µ–Ω—Ç –≤ –Ω–∞—á–∞–ª–æ —Å–ø–∏—Å–∫–∞"""
        with self._lock:
            if key not in self._data:
                self._data[key] = "[]"  # –•—Ä–∞–Ω–∏–º –∫–∞–∫ JSON —Å—Ç—Ä–æ–∫—É
            
            try:
                data_list = json.loads(self._data[key])
            except:
                data_list = []
            
            data_list.insert(0, value)
            self._data[key] = json.dumps(data_list)
            self._save_to_file()
            logger.debug(f"Redis LPUSH: {key} <- {value}")
            return len(data_list)

    def rpop(self, key: str) -> Optional[str]:
        """–£–¥–∞–ª—è–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞"""
        self._load_from_file()  # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        
        with self._lock:
            if key not in self._data:
                return None
            
            try:
                data_list = json.loads(self._data[key])
            except:
                return None
            
            if len(data_list) == 0:
                return None
            
            value = data_list.pop()
            self._data[key] = json.dumps(data_list)
            self._save_to_file()
            logger.debug(f"Redis RPOP: {key} -> {value}")
            return value

    def llen(self, key: str) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–ª–∏–Ω—É —Å–ø–∏—Å–∫–∞"""
        self._load_from_file()  # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        
        if key not in self._data:
            return 0
        
        try:
            data_list = json.loads(self._data[key])
            return len(data_list)
        except:
            return 0

    def lrem(self, key: str, count: int, value: str) -> int:
        """–£–¥–∞–ª—è–µ—Ç —ç–ª–µ–º–µ–Ω—Ç—ã –∏–∑ —Å–ø–∏—Å–∫–∞"""
        with self._lock:
            if key not in self._data:
                return 0
            
            try:
                data_list = json.loads(self._data[key])
            except:
                return 0
            
            removed = 0
            if count == 0:  # –£–¥–∞–ª–∏—Ç—å –≤—Å–µ
                removed = data_list.count(value)
                data_list = [item for item in data_list if item != value]
            elif count > 0:  # –£–¥–∞–ª–∏—Ç—å count —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –Ω–∞—á–∞–ª–∞
                for i in range(len(data_list) - 1, -1, -1):
                    if data_list[i] == value and removed < count:
                        del data_list[i]
                        removed += 1
            else:  # –£–¥–∞–ª–∏—Ç—å count —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –∫–æ–Ω—Ü–∞
                for i in range(len(data_list)):
                    if data_list[i] == value and removed < abs(count):
                        del data_list[i]
                        removed += 1
                        break
            
            self._data[key] = json.dumps(data_list)
            self._save_to_file()
            logger.debug(f"Redis LREM: {key} count={count} value={value} removed={removed}")
            return removed
    
    def publish(self, channel: str, message: str) -> int:
        """–ü—É–±–ª–∏–∫—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∫–∞–Ω–∞–ª"""
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å–æ–æ–±—â–µ–Ω–∏—è —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
        timestamp = int(time.time() * 1000000)  # –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥—ã
        message_file = os.path.join(self.messages_dir, f"{channel}_{timestamp}.json")
        
        message_data = {
            'channel': channel,
            'data': message,
            'timestamp': timestamp,
            'created_at': datetime.now().isoformat()
        }
        
        try:
            with open(message_file, 'w') as f:
                json.dump(message_data, f)
            
            logger.info(f"Redis PUBLISH: {channel} -> {message}")
            return 1  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ (—Å–∏–º—É–ª–∏—Ä—É–µ–º)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {e}")
            return 0
    
    def pubsub(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç PubSub"""
        return FakePubSub(self.messages_dir)

class FakePubSub:
    """–≠–º—É–ª—è—Ç–æ—Ä Redis PubSub —Å —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π"""
    
    def __init__(self, messages_dir: str):
        self.messages_dir = messages_dir
        self.subscribed_channels = set()
        self._last_check = 0
        
    def subscribe(self, *channels):
        """–ü–æ–¥–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –∫–∞–Ω–∞–ª—ã"""
        for channel in channels:
            self.subscribed_channels.add(channel)
            logger.info(f"FakePubSub: –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ {channel}")
    
    def listen(self):
        """–°–ª—É—à–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤"""
        logger.info(f"FakePubSub: –Ω–∞—á–∏–Ω–∞–µ–º —Å–ª—É—à–∞—Ç—å –∫–∞–Ω–∞–ª—ã: {self.subscribed_channels}")
        processed_files = set()  # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        
        while True:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å–æ–æ–±—â–µ–Ω–∏–π
                current_time = int(time.time() * 1000000)
                
                if not os.path.exists(self.messages_dir):
                    time.sleep(0.1)
                    continue
                
                for filename in os.listdir(self.messages_dir):
                    if not filename.endswith('.json'):
                        continue
                    
                    # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
                    if filename in processed_files:
                        continue
                    
                    filepath = os.path.join(self.messages_dir, filename)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –µ—â–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                    if not os.path.exists(filepath):
                        continue
                    
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞
                        file_timestamp = int(filename.split('_')[-1].replace('.json', ''))
                        
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                        if file_timestamp <= self._last_check:
                            processed_files.add(filename)
                            continue
                        
                        # –ß–∏—Ç–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
                        with open(filepath, 'r') as f:
                            message_data = json.load(f)
                        
                        channel = message_data['channel']
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–ø–∏—Å–∫—É –Ω–∞ –∫–∞–Ω–∞–ª
                        if channel in self.subscribed_channels:
                            yield {
                                'type': 'message',
                                'channel': channel,
                                'data': message_data['data']
                            }
                            
                            logger.info(f"üì® FakePubSub –ø–æ–ª—É—á–∏–ª: {channel} -> {message_data['data']}")
                        
                        # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ
                        processed_files.add(filename)
                        
                        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ —É–¥–∞–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                        try:
                            os.remove(filepath)
                        except FileNotFoundError:
                            pass  # –§–∞–π–ª —É–∂–µ —É–¥–∞–ª–µ–Ω –¥—Ä—É–≥–∏–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º
                            
                    except (json.JSONDecodeError, ValueError, KeyError) as e:
                        logger.warning(f"–ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ {filename}: {e}")
                        try:
                            os.remove(filepath)
                        except FileNotFoundError:
                            pass
                        processed_files.add(filename)
                        
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è {filename}: {e}")
                        processed_files.add(filename)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                self._last_check = current_time
                
                # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏
                if len(processed_files) > 1000:
                    processed_files.clear()
                
                time.sleep(0.1)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏
                
            except Exception as e:
                logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ FakePubSub.listen: {e}")
                time.sleep(1)

# Singleton —ç–∫–∑–µ–º–ø–ª—è—Ä
_fake_redis_instance = None

def get_fake_redis():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç singleton —ç–∫–∑–µ–º–ø–ª—è—Ä FakeRedis"""
    global _fake_redis_instance
    if _fake_redis_instance is None:
        _fake_redis_instance = FakeRedisFileBased()
    return _fake_redis_instance 